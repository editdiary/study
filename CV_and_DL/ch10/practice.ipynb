{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10-1. Farneback 알고리즘으로 광류 추정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import sys\n",
    "\n",
    "def draw_OpticalFlow(img, flow, step=16):\n",
    "    for y in range(step//2, frame.shape[0], step):\n",
    "        for x in range(step//2, frame.shape[1], step):\n",
    "            dx, dy = flow[y,x].astype(np.int)\n",
    "            if (dx*dx + dy*dy) > 1:\n",
    "                cv.line(img, (x,y), (x+dx, y+dy), (0,0,255), 2)     # 큰 모션이 있는 곳은 빨간색\n",
    "            else:\n",
    "                cv.line(img, (x,y), (x+dx, y+dx), (0,255,0), 2)\n",
    "    \n",
    "cap = cv.VideoCapture(0,  cv.CAP_DSHOW)     # 카메라와 연결 시도\n",
    "if not cap.isOpened(): sys.exit('카메라 연결 실패')\n",
    "\n",
    "prev = None\n",
    "\n",
    "while(1):\n",
    "    ret, frame = cap.read()                 # 비디오를 구성하는 프레임 획득\n",
    "    if not ret: sys('프레임 획득에 실패하여 루프를 나갑니다.')\n",
    "\n",
    "    if prev is None:                        # 첫 프레임이면 광류 계산 없이 prev만 설정\n",
    "        prev = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "        continue\n",
    "\n",
    "    curr = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    flow = cv.calcOpticalFlowFarneback(prev, curr, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "    draw_OpticalFlow(frame, flow)\n",
    "    cv.imshow('Optical flow', frame)\n",
    "\n",
    "    prev = curr\n",
    "\n",
    "    key = cv.waitKey(1)     # 1밀리초 동안 키보드 입력 기다림\n",
    "    if key == ord('q'):     # 'q' 키가 들어오면 루프를 빠져나감\n",
    "        break\n",
    "\n",
    "cap.release()               # 카메라와 연결을 끊음\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10-2. KLT 추적 알고리즘으로 물체 추적하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "cap = cv.VideoCapture('slow_traffic_small.mp4')\n",
    "\n",
    "feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n",
    "lk_params = dict(winSize=(15,15), maxLevel=2, criteria=(cv.TERM_CRITERIA_EPS|cv.TERM_CRITERIA_COUNT,10,0.03))\n",
    "\n",
    "color = np.random.randint(0, 255, (100, 3))\n",
    "\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv.cvtColor(old_frame, cv.COLOR_BGR2GRAY)\n",
    "p0 = cv.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
    "\n",
    "mask = np.zeros_like(old_frame)\n",
    "\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "\n",
    "    new_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    p1, match, err = cv.calcOpticalFlowPyrLK(old_gray, new_gray, p0, None, **lk_params)\n",
    "\n",
    "    if p1 is not None:\n",
    "        good_new = p1[match==1]\n",
    "        good_old = p0[match==1]\n",
    "\n",
    "    for i in range(len(good_new)):\n",
    "        a, b = int(good_new[i][0]), int(good_new[i][1])\n",
    "        c, d = int(good_old[i][0]), int(good_old[i][1])\n",
    "        mask = cv.line(mask, (a,b), (c,d), color[i].tolist(), 2)\n",
    "        frame = cv.circle(frame, (a,b), 5, color[i].tolist(), -1)\n",
    "\n",
    "    img = cv.add(frame, mask)\n",
    "    cv.imshow('LTK tracker', img)\n",
    "    cv.waitKey(30)\n",
    "\n",
    "    old_gray = new_gray.copy()\n",
    "    p0 = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10-3. SORT로 사람 추적하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import sys\n",
    "\n",
    "# [9-1 예제와 동일 (YOLOv3로 물체를 검출하는 함수)]\n",
    "def construct_yolo_v3():\n",
    "    f = open('coco_names.txt', 'r')\n",
    "    class_names = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    model = cv.dnn.readNet('yolov3.weights', 'yolov3.cfg')\n",
    "    layer_names = model.getLayerNames()\n",
    "    out_layers = [layer_names[i-1] for i in model.getUnconnectedOutLayers()]        # getUnconnectedOutLayers()는 출력 레이어의 인덱스를 반환\n",
    "\n",
    "    return model, out_layers, class_names\n",
    "\n",
    "def yolo_detect(img, yolo_model, out_layers):\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    test_img = cv.dnn.blobFromImage(img, 1.0/256, (448, 448), (0, 0, 0), swapRB=True)   # img, scalefactor, size, mean, swapRB\n",
    "\n",
    "    yolo_model.setInput(test_img)\n",
    "    output3 = yolo_model.forward(out_layers)\n",
    "\n",
    "    box, conf, id = [], [], []          # 박스, 신뢰도, 부류 번호\n",
    "    for output in output3:\n",
    "        for vec85 in output:\n",
    "            scores = vec85[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:        # 신뢰도가 50% 이상인 경우만 취함\n",
    "                center_x, center_y = int(vec85[0]*width), int(vec85[1]*height)\n",
    "                w, h = int(vec85[2]*width), int(vec85[3]*height)\n",
    "                x, y = int(center_x-w/2), int(center_y-h/2)\n",
    "                box.append([x, y, x+w, y+h])\n",
    "                conf.append(float(confidence))\n",
    "                id.append(class_id)\n",
    "\n",
    "    ind = cv.dnn.NMSBoxes(box, conf, 0.5, 0.4)        # box, conf, score_threshold, nms_threshold\n",
    "    objects = [box[i] + [conf[i]] + [id[i]] for i in range(len(box)) if i in ind]\n",
    "    return objects\n",
    "\n",
    "model, out_layers, class_names = construct_yolo_v3()        # YOLO 모델 생성\n",
    "colors = np.random.uniform(0, 255, size=(100,3))            # 100개 색으로 트랙 구분\n",
    "\n",
    "from sort import Sort\n",
    "\n",
    "sort = Sort()\n",
    "\n",
    "cap = cv.VideoCapture(0, cv.CAP_DSHOW)\n",
    "if not cap.isOpened(): sys.exit('카메라 연결 실패')\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: sys.exit('프레임 획득에 실패하여 루프를 나갑니다.')\n",
    "\n",
    "    res = yolo_detect(frame, model, out_layers)\n",
    "    persons = [res[i] for i in range(len(res)) if res[i][5]==0]\n",
    "\n",
    "    if len(persons) == 0:\n",
    "        tracks = sort.update()\n",
    "    else:\n",
    "        tracks = sort.update(np.array(persons))\n",
    "\n",
    "    for i in range(len(tracks)):\n",
    "        x1, y1, x2, y2, track_id = tracks[i].astype(int)\n",
    "        cv.rectangle(frame, (x1,y1), (x2,y2), colors[track_id], 2)\n",
    "        cv.putText(frame, str(track_id), (x1+10, y1+40), cv.FONT_HERSHEY_PLAIN, 3, colors[track_id], 2)\n",
    "\n",
    "    cv.imshow('Person tracking by SORT', frame)\n",
    "\n",
    "    key = cv.waitKey(1)\n",
    "    if key == ord('q'): break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
